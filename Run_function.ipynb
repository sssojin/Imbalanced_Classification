{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 1886"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used dataset from imblearn\n",
    "datasets = imblearn.datasets.fetch_datasets()['wine_quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary to a pandas dataframe\n",
    "df = pd.concat([pd.DataFrame(datasets['data'], columns = [f'data_{i}' for i in range(datasets.data.shape[1])]),\n",
    "                pd.DataFrame(datasets['target'], columns = ['target'])], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before preprocess:  [-1  1]\n",
      " after preprocess:  [0 1]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for target value\n",
    "print('before preprocess: ', df['target'].unique())\n",
    "df['target'] = df['target'].replace(-1, 0)\n",
    "print(' after preprocess: ', df['target'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of minor class:  183\n",
      "number of major class:  4715\n",
      "  IR(Imbalance Ratio): 25\n"
     ]
    }
   ],
   "source": [
    "# define IR\n",
    "num_major = df['target'].value_counts().sort_values()[0]\n",
    "num_minor = df['target'].value_counts().sort_values()[1]\n",
    "IR = int(num_major/num_minor)\n",
    "\n",
    "print('number of minor class: ', num_minor)\n",
    "print('number of major class: ', num_major)\n",
    "print('  IR(Imbalance Ratio): {0:.0f}'.format(IR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis = 1), \n",
    "                                                    df['target'], \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3918, 11), (980, 11))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate IDCP\n",
    "def cal_IDCP(y, pred):\n",
    "    f1 = f1_score(y,pred)\n",
    "    roc_score = roc_auc_score(y, pred, average='macro')\n",
    "    IDCP = np.round((2*f1+roc_score)/3, 4)\n",
    "    return IDCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted values from selected model\n",
    "def model_eval(model, X_train, y_train, weights):\n",
    "    weights_y = pd.DataFrame(compute_sample_weight(weights, y_train), columns = ['weight'])\n",
    "\n",
    "    if model == 'LR':\n",
    "        base_model = LogisticRegression(random_state=random_seed, class_weight=weights)\n",
    "        base_model.fit(X_train, y_train)\n",
    "    elif model == 'SVM':\n",
    "        base_model = SVC(random_state=random_seed, class_weight=weights)\n",
    "        base_model.fit(X_train, y_train)\n",
    "    elif model == 'RF':\n",
    "        base_model = RandomForestClassifier(n_estimators=500, max_depth=8, max_features=5, \n",
    "                                            random_state=random_seed, class_weight=weights)\n",
    "        base_model.fit(X_train, y_train)\n",
    "    elif model == 'XGB':\n",
    "        # gridsearch\n",
    "        XGB = XGBClassifier(eval_metric='mlogloss', use_label_encoder=False)\n",
    "        param_grid={'n_estimators' : [50,100],\n",
    "                    'learning_rate' : [0.01,0.05,0.1],\n",
    "                    'max_depth' : [3,5,7]}\n",
    "        cv=KFold(n_splits=3)\n",
    "        Grid_XGB=GridSearchCV(XGB, param_grid=param_grid, cv=cv, scoring=make_scorer(cal_IDCP), n_jobs=4)\n",
    "        Grid_XGB.fit(X_train, y_train)\n",
    "        base_model = Grid_XGB.best_estimator_\n",
    "        base_model.fit(X_train, y_train, sample_weight=weights_y)\n",
    "    elif model == 'CB':\n",
    "        # gridsearch\n",
    "        CBC = CatBoostClassifier()\n",
    "        param_grid={'depth'         : [4,5,6],\n",
    "                    'learning_rate' : [0.01,0.05,0.1,0.2,0.3],\n",
    "                    'iterations'    : [30,40,50,60,70,80]}\n",
    "        Grid_CBC = GridSearchCV(estimator=CBC, param_grid = param_grid, cv = 2, scoring=make_scorer(cal_IDCP), n_jobs=-1)\n",
    "        Grid_CBC.fit(X_train, y_train, verbose=False)\n",
    "        base_model = Grid_CBC.best_estimator_\n",
    "        base_model.fit(X_train, y_train, sample_weight=weights_y, verbose=False)\n",
    "\n",
    "    pred = base_model.predict(X_train)\n",
    "\n",
    "    return base_model, pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can choose among 'LR', 'SVM', 'RF', 'XGB', 'CB'\n",
    "\n",
    "model = 'XGB'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.39\n"
     ]
    }
   ],
   "source": [
    "weights = {0:1.0, 1:1.0} # initial weight\n",
    "base_model, pred = model_eval(model, X_train, y_train, weights)\n",
    "recall = recall_score(y_train, pred)\n",
    "print('Recall: {0:.2f}'.format(recall))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimal weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  25 , IDCP:  0.6711\n",
      "w:  24 , IDCP:  0.68\n",
      "w:  23 , IDCP:  0.6817\n",
      "w:  22 , IDCP:  0.6813\n",
      "w:  21 , IDCP:  0.6854\n",
      "w:  20 , IDCP:  0.6783\n",
      "w:  19 , IDCP:  0.7006\n",
      "w:  18 , IDCP:  0.686\n",
      "------------------------------\n",
      "optimal w:  19\n"
     ]
    }
   ],
   "source": [
    "weight_list = []\n",
    "IDCP_list = []\n",
    "patience_check = 0 # Record the number of epochs not improving consecutively  \n",
    "patience_limit = 3 # Decide the number of epochs to allow in early stopping\n",
    "\n",
    "if recall >= 0.5:\n",
    "    potential_range = range(1, IR+1)\n",
    "else:\n",
    "    potential_range = range(IR, 0, -1)\n",
    "\n",
    "for i, w in enumerate(potential_range):\n",
    "    weights = {0:1.0, 1:w}\n",
    "    weights_y = pd.DataFrame(compute_sample_weight(weights, y_train), columns = ['weight'])\n",
    "\n",
    "    base_model, pred = model_eval(model, X_train, y_train, weights)\n",
    "    IDCP = cal_IDCP(y_train, pred)\n",
    "    print('w: ', w, ', IDCP: ', IDCP)\n",
    "    weight_list.append(w)\n",
    "    IDCP_list.append(IDCP)\n",
    "\n",
    "    # early stopping\n",
    "    if IDCP_list[i-1] > IDCP:\n",
    "        patience_check += 1\n",
    "    if patience_check >= patience_limit:\n",
    "        break\n",
    "optimal_w = weight_list[np.argmax(IDCP_list)]\n",
    "print('---'*10)\n",
    "print('optimal w: ', optimal_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
